{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b15f93",
   "metadata": {},
   "source": [
    "Description: This notebook implements a defect detection system using a pre-trained CNN (ResNet50) on the MVTec AD dataset.\n",
    "\n",
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d992be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481deb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4640ebf",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation\n",
    "Assume you have preprocessed the MVTec AD dataset into `train/normal`, `train/defect`, `test/normal`, `test/defect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab71b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8ecb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "class MVTecBinaryClassificationDataset(Dataset):\n",
    "    def __init__(self, root_dir, item_name, split='train', transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "\n",
    "        base_path = os.path.join(root_dir, item_name, split)\n",
    "        if split == 'train':\n",
    "            good_images = glob(os.path.join(base_path, 'good', '*.png'))\n",
    "            self.samples += good_images\n",
    "            self.labels += [0] * len(good_images)\n",
    "        elif split == 'test':\n",
    "            for defect_type in os.listdir(base_path):\n",
    "                defect_path = os.path.join(base_path, defect_type)\n",
    "                images = glob(os.path.join(defect_path, '*.png'))\n",
    "                label = 0 if defect_type == 'good' else 1\n",
    "                self.samples += images\n",
    "                self.labels += [label] * len(images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2eb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_name = 'bottle'  # Change this to the item you are evaluating\n",
    "\n",
    "train_dataset = MVTecBinaryClassificationDataset(\n",
    "    root_dir='mvtec_anomaly_detection',\n",
    "    item_name=item_name,\n",
    "    split='train',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = MVTecBinaryClassificationDataset(\n",
    "    root_dir='mvtec_anomaly_detection',\n",
    "    item_name=item_name,\n",
    "    split='test',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9157f50",
   "metadata": {},
   "source": [
    "## Step 3: Load and Fine-tune the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35bb9d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DL\\visual-defect-detection-transfer-learning\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\DL\\visual-defect-detection-transfer-learning\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\ankim/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a15c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # freeze base layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1427a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace final layer for binary classification\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd424643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c17fe353",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fae6ec",
   "metadata": {},
   "source": [
    "## Step 4: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a83fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc89cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1127, Accuracy: 0.9665\n",
      "Epoch 2, Loss: 0.0001, Accuracy: 1.0000\n",
      "Epoch 3, Loss: 0.0000, Accuracy: 1.0000\n",
      "Epoch 4, Loss: 0.0000, Accuracy: 1.0000\n",
      "Epoch 5, Loss: 0.0000, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85651f",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48f00f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=test_dataset.classes, yticklabels=test_dataset.classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d4aba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MVTecBinaryClassificationDataset' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m     11\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(all_labels, all_preds, target_names\u001b[38;5;241m=\u001b[39m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m))\n\u001b[0;32m     16\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(all_labels, all_preds)\n\u001b[0;32m     17\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, xticklabels\u001b[38;5;241m=\u001b[39mtest_dataset\u001b[38;5;241m.\u001b[39mclasses, yticklabels\u001b[38;5;241m=\u001b[39mtest_dataset\u001b[38;5;241m.\u001b[39mclasses)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MVTecBinaryClassificationDataset' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b823d7",
   "metadata": {},
   "source": [
    "Step 6: Visualizing with Grad-CAM (Optional Advanced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
